ltdb.http.host=0.0.0.0
ltdb.http.ports=8080

ltdb.http.request-log-retain.days=5

# https
#ltdb.http.keystore=
#ltdb.http.keystore.password=
#ltdb.http.key-password=

# spark
# ltdb.spark.hadoopUserName=svcapp_su
ltdb.spark.master=local[*]
# ltdb.spark.master=yarn-client
# ltdb.spark.submit.deployMode=client
# ltdb.spark.yarn.stagingDir=hdfs://BPP-TVIEW-AIOPS-SEARCH01:9001/user/svcapp_su
ltdb.spark.sql.crossJoin.enabled=true
# ltdb.spark.driver.allowMultipleContexts=true
# ltdb.spark.yarn.jars=hdfs://BPP-TVIEW-AIOPS-SEARCH01:9001/tmp/ltdb-http-1.0-SNAPSHOT-with-deps.jar
# ltdb.spark.yarn.queue=default
# ltdb.spark.yarn.am.cores=1
# ltdb.spark.yarn.am.memory=512m
# ltdb.spark.yarn.am.memoryOverhead=1024

# ltdb.spark.driver.memory=4096m
# ltdb.spark.executor.cores=10
# ltdb.spark.executor.memory=4096m
# ltdb.spark.executor.instances=9
#ltdb.spark.sql.hive.thriftServer.singleSession=true

#kubernetes
# ltdb.spark.master=k8s://http://10.0.0.10:8001
# ltdb.http.resource.dirs=k8s-jars
# ltdb.spark.submit.deployMode=client
# ltdb.spark.jars=http://192.168.0.21:8080/k8s-jars/ltdb-http-1.0-SNAPSHOT-with-deps.jar
# ltdb.spark.kubernetes.container.image=gradiant/spark:2.4.0
# ltdb.spark.kubernetes.container.image.pullPolicy=IfNotPresent
# ltdb.spark.kubernetes.namespace=default
# ltdb.spark.driver.host=192.168.0.21
#
# ltdb.spark.driver.memory=1024m
# ltdb.spark.executor.cores=1
# ltdb.spark.executor.memory=1024m
# ltdb.spark.executor.instances=3
# ltdb.spark.dynamicAllocation.enabled=false